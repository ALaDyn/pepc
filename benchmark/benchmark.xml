<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE jube SYSTEM "<jube.dtd path>">
<jube>
   <benchmark name="PEPC Benchmark" outpath="../run/benchmark">

      <!-- ############################################################################################ -->
      <!-- the benchmark will copy all sources, compile PEPC and initiate a number of runs              -->
      <!--    after runs are finished, a table of results may be printed                                -->
      <!--                                                                                              -->
      <!-- thoughout this file, several different tags will be used to switch the benchmark's behaviour -->
      <!--                                                                                              -->
      <!--    the tags are named m<xxx> to enable _m_ultiple xxx                                        -->
      <!--    xxx=threads: scans a varying number of threads per node                                   -->
      <!--    xxx=iter   : perfom 10 iterations                                                         -->
      <!--    xxx=mpi    : change the environment to load different MPI versions                        -->
      <!--                                                                                              -->

      <!-- PARAMETER SETS ############################################################################# -->
      <!-- set up different MPI environments -->
      <parameterset name="mpiset">
	 <!--possible choices: intel_intel, gcc_mvapich, intel_mvapich, gcc_ps, gcc_pssilly, gcc_ompi, gcc_ompi_nb, gcc_ps_pin, gcc_ps_new, gcc_ps_new_malloc, gcc_ps_old, gcc_ps_old_rdzv -->
	 <parameter tag="mps" name="mpi">gcc_ps_new, gcc_ps_new_malloc, gcc_ps_old, gcc_ps_old_rdzv</parameter>
	 <parameter tag="mmpi" name="mpi">gcc_ps_pin, gcc_mvapich, gcc_ompi</parameter>
	 <parameter tag="!mmpi,!mps" name="mpi">gcc_ps_pin</parameter>
      </parameterset>
      <!-- define all parameter set we possibly use to benchmark -->
      <parameterset name="nodeset">
	 <!-- Jureca has 2 x 12 cores, SMT, PEPC uses 1 comm thread, the rest remains for workers -->
	 <!--parameter name="nodes" type="int">2, 4, 8, 16, 32, 64</parameter-->
	 <parameter name="nodes" type="int">2, 4</parameter>
	 <parameter name="taskspnode" type="int">1, 2</parameter>
	 <parameter name="threads" mode="python" type="int">",".join(str(int(HWT/${taskspnode})) for HWT in [24,48])</parameter>
	 <parameter name="workerthreads" mode="python" type="int">$threads-1</parameter>
	 <!-- weak scaling with constant number of particles per thread -->
	 <parameter tag="weak"  name="particles" mode="python" type="int">int($workerthreads*$taskspnode*$nodes*10000)</parameter>
	 <!-- strong scaling with constant number of particles -->
	 <parameter tag="!weak" name="particles"               type="int">10000000</parameter>
      </parameterset>

      <!-- FILE SETS ################################################################################## -->
      <!-- copy environment setter -->
      <fileset name="environment">
	 <copy directory=".">prepare_env.sh</copy>
      </fileset>
      <!-- copy all souce files -->
      <fileset name="sources">
	 <copy directory="../.">makefile, makefile.defs_*, makefiles, src, tools, show_affinity.x</copy>
      </fileset>
      <!-- link executable -->
      <fileset name="executable">
	 <link rel_path_ref="internal">compile/bin/pepc-benchmark</link>
	 <link rel_path_ref="internal">compile/show_affinity.x</link>
      </fileset>
      <!-- copy all files to run later -->
      <fileset name="runfiles">
	 <copy directory=".">params.skel, job_jureca.slurm.skel</copy>
      </fileset>

      <!-- SUBSTITUIONS ############################################################################### -->
      <!-- define the substitute sets for parameters above, to be enabled individually -->
      <substituteset name="inputsub">
	 <iofile in="params.skel" out="params" />
	 <sub source="##SETUP##" dest="'benchmark'" />
	 <sub source="##THREADS##" dest="$workerthreads" />
	 <sub source="##DIAG##" dest=".false." />
	 <sub source="##DT##" dest="0.1e-1" />
	 <sub source="##NT##" dest="100" />
	 <sub source="##NPARTICLES##" dest="$particles" />
      </substituteset>
      <substituteset name="runsub">
	 <iofile in="job_jureca.slurm.skel" out="job_jureca.slurm" />
	 <sub source="##MPI##" dest="$mpi" />
	 <sub source="##NODES##" dest="$nodes" />
	 <sub source="##TASKSPNODE##" dest="$taskspnode" />
	 <sub source="##THREADS##" dest="$threads" />
      </substituteset>

      <!-- JOB STEPS ################################################################################## -->
      <!-- compile the code, apply substitutions as necessary -->
      <step name="compile">
	 <use>environment</use>
	 <use>sources</use>
	 <use>mpiset</use>
	 <do done_file="bin/pepc-benchmark">./prepare_env.sh $mpi</do>
      </step>
      <!-- run the binary, apply substitutions as necessary -->
      <step tag="!miter" name="run" depend="compile" iterations="1">
	 <use>mpiset</use>
	 <use>nodeset</use>
	 <use>environment</use>
	 <use>executable</use>
	 <use>runfiles</use>
	 <use>inputsub</use>
	 <use>runsub</use>
	 <do done_file="the_eagle_has_landed">sbatch -p mem512 --gres=mem512 job_jureca.slurm</do>
      </step>
      <step tag="miter" name="run" depend="compile" iterations="10">
	 <use>mpiset</use>
	 <use>nodeset</use>
	 <use>environment</use>
	 <use>executable</use>
	 <use>runfiles</use>
	 <use>inputsub</use>
	 <use>runsub</use>
	 <do done_file="the_eagle_has_landed">sbatch -p mem512 --gres=mem512 job_jureca.slurm</do>
      </step>

      <!-- OUTPUT ANALYSIS ############################################################################ -->
      <!-- define timing patternset -->
      <!-- Regex pattern -->
      <patternset name="timing_pattern">
	 <pattern unit="secs" name="wallclock" type="float">===== total run time \[s\]:\s+${jube_pat_fp}</pattern>
	 <pattern unit="secs" name="tree_walk" type="float">====== tree walk time  :\s+${jube_pat_fp}</pattern>
	 <pattern unit="secs" name="tree_grow" type="float">====== tree grow time  :\s+${jube_pat_fp}</pattern>
	 <pattern unit="secs" name="step_time" type="float">== time in step.*:\s+${jube_pat_fp}</pattern>
      </patternset>
      <!-- ====== tree walk time  :  8.7359E-02  // many of those
	   [...]
	   ===== total run time [s]:   2.8961E+03
	   BLOODY REGEX!!@$!

           ====== computing step  :           0
           ====== simulation time :  0.0000E+00
           ====== tree grow time  :  3.7220E-01
           ====== tree walk time  :  7.2144E+00
           == [pusher] push particles 
           == time in step [s]                              :   1.2952E+01
                      t_all =    12.9479424953 s
                      t_tot =     0.0000000000 s

       -->

      <!-- TABLE OUTPUT ############################################################################### -->
      <!-- Analyse timings -->
      <analyser name="analysis">
	 <use>timing_pattern</use> <!-- use existing patternset -->
	 <analyse step="run">
	    <file>log</file> <!-- file which should be scanned -->
	 </analyse>
      </analyser>
      <analyser name="single_analysis" reduce="false">
	 <use>timing_pattern</use> <!-- use existing patternset -->
	 <analyse step="run">
	    <file>log</file> <!-- file which should be scanned -->
	 </analyse>
      </analyser>

      <!-- Create result table -->
      <result>
	 <use>analysis</use> <!-- use existing analyser -->
	 <table name="result" style="pretty" sort="threads">
	    <column tag="mmpi, mps"          >mpi</column>
	    <column                          >nodes</column>
	    <column                          >taskspnode</column>
	    <column                          >threads</column>
	    <column                          >particles</column>
	    <column              format=".2f">tree_grow_max</column>
	    <column              format=".2f">tree_grow_avg</column>
	    <column              format=".2f">tree_grow_min</column>
	    <column              format=".2f">tree_walk_max</column>
	    <column              format=".2f">tree_walk_avg</column>
	    <column              format=".2f">tree_walk_min</column>
	    <column                          >tree_walk_cnt</column>
	    <column              format=".2f">step_time_max</column>
	    <column              format=".2f">step_time_avg</column>
	    <column              format=".2f">step_time_min</column>
	    <column tag="miter"  format=".2f">wallclock_avg</column>
	    <column tag="miter"  format=".2f">wallclock_min</column>
	    <column tag="miter"              >wallclock_cnt</column>
	    <column tag="!miter" format=".2f">wallclock</column>
	 </table>
      </result>
      <result>
	 <use>single_analysis</use> <!-- use existing analyser -->
	 <table name="single_result" style="pretty" sort="threads">
	    <column                        >jube_wp_iteration</column>
	    <column tag="mmpi, mps"        >mpi</column>
	    <column                        >nodes</column>
	    <column                        >taskspnode</column>
	    <column                        >threads</column>
	    <column                        >particles</column>
	    <column            format=".2f">tree_grow_max</column>
	    <column            format=".2f">tree_grow_avg</column>
	    <column            format=".2f">tree_grow_min</column>
	    <column            format=".2f">tree_walk_max</column>
	    <column            format=".2f">tree_walk_avg</column>
	    <column            format=".2f">tree_walk_min</column>
	    <column                        >tree_walk_cnt</column>
	    <column            format=".2f">step_time_max</column>
	    <column            format=".2f">step_time_avg</column>
	    <column            format=".2f">step_time_min</column>
	    <column            format=".2f">wallclock</column>
	 </table>
      </result>

   </benchmark>
</jube>
